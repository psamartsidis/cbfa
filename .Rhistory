d=review[[4]][1:25] #
e=review[[5]][1:25]
f=review[[6]][1:25]
g=review[[7]][1:25]
a
b
common(a,b)
intersect
intersect(a,b)
# Subgroup Analysis Review -- Random Assignments of Papers
#install.packages("iterpc")
set.seed(210721) #original seed used for assignment list
names       <- c("AM", "FW", "CY", "JS", "JW", "MG", "NN")
pairs       <- iterpc::getall(iterpc::iterpc(n       = length(names),
r       = 2,
labels  = names,
ordered = FALSE,
replace = TRUE))
pairs <- pairs[(pairs[, 1] != pairs[, 2]), ]
#keep  <- !( (pairs[,1]=="FW2" & pairs[,2]== "FW") | (pairs[,1]=="FW" & pairs[,2]== "FW2") )
#pairs <- pairs[keep, ]
#omit the following row numbers
pilot_AA <- c(181,291,125,252,111,362,207,71,23,50)
pilot_JJ <- c(344,318,178,235,296,89,400,22, 62,25)
pilot_MN <- c(236,147,229,188,66,257,100,53,74,45)
pilot_CF <- c(190,272,47,31,68,42,73,60,21,30)
pilot_FW <- 1:(75 - length(c(70,22,49,21,61,24,52,74,44,46,30,67,41,72,59,20,29)))
omit        <- c(pilot_AA,pilot_JJ,pilot_MN,pilot_CF)
papers      <- 410 - length(omit)  # number of papers left to review
assignments <- matrix(NA, papers, 2)
row_id <- 1:411
row_id <- row_id[-c(1,omit)]
for (i in 1:floor(papers/nrow(pairs))) {
assignments[(1 + (i - 1)*nrow(pairs)):(i*nrow(pairs)), ] <- pairs[sample.int(nrow(pairs), nrow(pairs)), ]
}
left        <- papers - nrow(pairs)*floor(papers/nrow(pairs))
assignments[(papers - left + 1):papers, ] <-  pairs[sample.int(nrow(pairs), left), ]
index_replace=NULL
for (i in 1:length(pilot_FW)) {
if ( any(assignments[i,]=="FW")==F ) index_replace = c(index_replace,i) # rows without FW
}
index_fw=NULL
for (j in (length(pilot_FW) +1):papers) {
if ( any(assignments[j,]=="FW") ) index_fw = c(index_fw,j) # rows with FW in remaining
}
for (k in 1:length(index_replace)) {
tmp = assignments[index_replace[k],]
assignments[index_replace[k],] = assignments[index_fw[k],]
assignments[index_fw[k],]      = tmp # swap rows
}
review <- list()
for (i in 1:length(names)) {
review[[i]] <- row_id[which(assignments[,1]==names[i] | assignments[,2]==names[i])]
}
names(review) = names
review
save(review,file="random_assignment.RDa")
write.csv(review$AM,file="random_assignment_AM.csv",row.names=F)
write.csv(review$JS,file="random_assignment_JS.csv",row.names=F)
write.csv(review$JW,file="random_assignment_JW.csv",row.names=F)
write.csv(review$MG,file="random_assignment_MG.csv",row.names=F)
write.csv(review$NN,file="random_assignment_NN.csv",row.names=F)
write.csv(review$FW,file="random_assignment_FW.csv",row.names=F)
write.csv(review$CY,file="random_assignment_CY.csv",row.names=F)
#Step 1. Find which of the 1-75 assignemeent rows have no FW in (K of them): for loop with any()==FW to be  FALSE
#Step 2. Find which of 76-370 assigmements rows have FW in them (M of them): for loop with any()==FW
#Step 3. Loop the indices in step 1 and randomly swap with the rows found in step 2#
###
a=review[[1]][1:25] # adrian
b=review[[2]][1:25] # faye
#c=review[[3]][108:84] # christina EXCLUDE FOR INITIAL PHASE
d=review[[4]][1:25] #
e=review[[5]][1:25]
f=review[[6]][1:25]
g=review[[7]][1:25]
h=list(a,b,d,e,f,g)
length(unique(h))
tab=table(h)
sum(table(h)==2)
common_papers <- unique(c(intersect(a,b),intersect(a,d),intersect(a,e),intersect(a,f),intersect(a,g),
intersect(b,d),intersect(b,e),intersect(b,f),intersect(b,g),
#c==d | c==e | c==f | c==g |
intersect(d,e),intersect(d,f),intersect(d,g),
intersect(e,f),intersect(e,g),
intersect(f,g)))
common_papers=sort(common_papers)
common_papers
0.15*75
ceil(0.15*75)
ceiling(0.15*75)
pbinom(11,75,0.7)
pbinom(11,75,0.5)
pbinom(11,75,0.5)*1000000
library(rPG)
library(rpg)
library(pgdraw)
citation(pgdraw)
?citation
citation("pgdraw")
choose(3.2,1)
?choose
25*25
rm(list = ls())
# Dataset parameters
nUnits = 20
nTimes = 50
# Factor parameters
P = 1  # this is the total number of factors
factors  = matrix( NA, nTimes, P )
loadings = matrix( NA, nUnits, P )
ar_rho   = rep( 0.95, P )
ar_sd    = rep( 1, P )
# Simulate the factors (we have assumed that the mean is zero)
for ( j in 1:P ) {
factors[1,j] = rnorm(0,1)
for ( t in 2:nTimes ) {
factors[t,j] = ar_rho[j] * factors[t-1,j] + rnorm(1,0,ar_sd[j])
}
}
rm(list = ls())
# Dataset parameters
nUnits = 20
nTimes = 50
# Factor parameters
P = 1  # this is the total number of factors
factors  = matrix( NA, nTimes, P )
loadings = matrix( NA, nUnits, P )
ar_rho   = rep( 0.95, P )
ar_sd    = rep( 1, P )
# Simulate the factors (we have assumed that the mean is zero)
for ( j in 1:P ) {
factors[1,j] = rnorm(1,0,ar_sd[j])
for ( t in 2:nTimes ) {
factors[t,j] = ar_rho[j] * factors[t-1,j] + rnorm(1,0,ar_sd[j])
}
}
factors[,1]
plot(factors[,1])
plot(factors[,1],type='l')
# The following will plot the first factor
plot(factors[,1])
# The following will plot the first factor
plot( factors[,1], type='l', xlab='Time point', ylab='Value of factor', main='1st factor')
# Check the autocorrelation (see how this changes if you reduce ar_rho)
acf( factors[,1] )
# Check the autocorrelation (see how this changes if you reduce ar_rho)
acf( factors[,1], main='Autocorrelation of first factor' )
# Simulate the loadings
for ( i in 1:nUnits ) {
for (j in 1:P) {
loadings[i,j] = rnorm(1,0,1)
}
}
loadings
# Simulate the data
# First the systematic part (loadings/factors product)
y = factors %*% t(loadings)
y
dim(y)
library(lattice)
levelplot(y)
rm(list = ls())
# Dataset parameters
nUnits = 20
nTimes = 50
# Factor parameters
P = 1  # this is the total number of factors
factors  = matrix( NA, nTimes, P )
loadings = matrix( NA, nUnits, P )
ar_rho   = rep( 0.95, P )
ar_sd    = rep( 1, P )
# Simulate the factors (we have assumed that the mean is zero)
for ( j in 1:P ) {
factors[1,j] = rnorm(1,0,ar_sd[j])
for ( t in 2:nTimes ) {
factors[t,j] = ar_rho[j] * factors[t-1,j] + rnorm(1,0,ar_sd[j])
}
}
# The following will plot the first factor
plot( factors[,1], type='l', xlab='Time point', ylab='Value of factor', main='1st factor')
# Check the autocorrelation (see how this changes if you reduce ar_rho)
acf( factors[,1], main='Autocorrelation of first factor' )
# Simulate the loadings
for ( i in 1:nUnits ) {
for (j in 1:P) {
loadings[i,j] = rnorm(1,0,.5)
}
}
# Simulate the data
# First the systematic part (loadings/factors product)
y = factors %*% t(loadings)
# The columns of y represent the different units
# Then, the error/random component
sd_data = 0.1
for (i in 1:nUnits) {
for (t in 1:nTimes) {
y[t,i] = y[t,i] + rnorm(1,0,sd_data)
}
}
levelplot(y)
plot(y[,1])
# Dataset of the first unit
plot( y[,1], main='Data of 1st unit', xlab='Time point', ylab='Value of the outcome' )
# Check the autocorrelation
acf( y[,1])
# Check the autocorrelation
acf( y[,1], main='Autocorrelation of data of 1st unit')
plot(y[.2])
plot(y[,2])
900+80+31+14+13+45+14
2600-1097
4.5*(80+60)
1000-630
2600-1100-650
4.5*(120+70)
4.5*(105+65)
4.5*(105+60)
(120*60)*4.5
(120+60)*4.5
(100+60)*4.5
2600-1100-650
## set parameters, challenging case ##
a=1/20
b=c=100/20
mu=1
n=1e+4 # n. samples
# block 1 #
x=rnorm(n, mu , 1/sqrt(2*a)) # x is common to all blocks
y=rnorm(n, x^2, 1/sqrt(2*b) )
z=rnorm(n, y^2, 1/sqrt(2*c) )
# block 2 (including x, sampled above) #
u=rnorm(n, x^2, 1/sqrt(2*b) )
v=rnorm(n, u^2, 1/sqrt(2*c) )
resDir=matrix(c(x,y,z,u,v),length(x),5)
rm(x,y,z,u,v)
pairs(resDir, upper.panel = NULL) #standard R function
rw <- function(target, N, x, step, Sigma=diag(length(x)), thin=1)
{
ptm=proc.time()
#alpha=1e+6
cat("Tot run = N*thin = ",N*thin,"\n")
if ( sum(Sigma - diag(length(x)) )==0  ){
ident=TRUE
} else {
ident=FALSE
Sigma.chol <- t( chol(Sigma) )
}
dd=length(x)
acc=0
samples = matrix(0, N, length(x) )
samples[1,] <- x
run=N*thin
target_prop = target_x = target(x)
for (i in 2:run )
{
if(i%%(run/10)==0) cat("Progress:",i/run*100,"% \n") #track progress
if (ident) prop <- x + step*rnorm(dd)
else prop = x + step * Sigma.chol %*% rnorm(dd)
target_prop = target(prop)
if (runif(1) < exp( target_prop - target_x ) ){
x <- prop
acc = acc + 1
target_x = target_prop
}
if( (i%%thin)==0 ) samples[i/thin,] = x
}
time=proc.time()-ptm
cat('Run Time',round(time[1]/60,digits=2),'Min','\n')
#cat("Acc Rate",acc/run,"\n")
system(paste("echo Acc",acc/run))
return(list(samples,time[1]))
}
logTarget6=function(q){-a*(q[1]-mu)^2 -b*(q[2] - q[1]^2)^2 -b*(q[3] - q[2]^2)^2 -b*(q[4] - q[1]^2)^2 -b*(q[5] - q[4]^2)^2 } #U=+log
resRW=rw(logTarget6, 100000, matrix(1,5,1), .2)
pairs(resRW[[1]], upper.panel = NULL)
pairs(resRW[[1]], upper.panel = NULL)
logTarget6=function(q){-a*(q[1]-mu)^2 -b*(q[2] - q[1]^2)^2 -b*(q[3] - q[2]^2)^2 -b*(q[4] - q[1]^2)^2 -b*(q[5] - q[4]^2)^2 } #U=+log
resRW=rw(logTarget6, 100000, matrix(1,5,1), .2)
cleaqr
clear
q()
rm(list = ls())
Y = c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14,
4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
length(Y)
rm(list = ls())
Y = c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14,
4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
batch = factor(rep(c("Batch_1", "Batch_2"), each =  10))
sample_id = factor(rep(c("A", "B", "C", "D"), each =  5))
table(sample_id, batch)
# make design not symmetric:
sel = 1:18
Y = Y[sel]
batch = batch[sel]
sample_id = sample_id[sel]
batch
table(sample_id, batch)
sample_id = factor(rep(c("A", "B", "C", "D"), each =  c(5,6,7,8)))
sample_id = factor(rep(c("A", "B", "C", "D"), each =  5))
table(sample_id, batch)
# make design not symmetric:
sel = 1:18
Y = Y[sel]
batch = batch[sel]
sample_id = sample_id[sel]
# My original model, without sample id:
lm = lm(Y ~ batch )
lm
# a mixed effect model with sample id as random effect
library(lme4)
mm = lmer(Y ~ batch + (1|sample_id) )
# a mixed effect model with sample id as random effect
library(lme4)
install.packages('lme4')
install.packages('minqa')
install.packages('lme4')
install.packages('nloptr')
install.packages('processx')
install.packages('processx')
install.packages('R6')
install.packages('processx')
install.packages('nloptr')
install.packages("nloptr", repos="http://R-Forge.R-project.org")
install.packages("nloptr")
install.packages("lme4")
library(nloptr)
install.packages("nloptr")
library(devtools)
install.packages('devtools')
install.packages('stringr')
install.packages('stringi')
.libPaths()
# grab old packages names
old_packages <- installed.packages(lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
old_packages <- as.data.frame(old_packages)
list.of.packages <- unlist(old_packages$Package)
# remove old packages
remove.packages( installed.packages( priority = "NA" )[,1] )
1+1
# reinstall all packages
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages,function(x){library(x,character.only=TRUE)})
install.packages('lme4')
install.packages('Rcpp')
install.packages('Rcpp')
.libPaths()
.libPaths()[1]
ras = .libPaths()[1]
.libPaths()="/home/pantelis/R/x86_64-pc-linux-gnu-library/4.0"
.libPaths()=NULL
.libPaths="/home/pantelis/R/x86_64-pc-linux-gnu-library/4.0"
.libPaths
install.packages('lme4')
install.packages('nloptr')
q()
install.packages('nloptr')
Url = https://cran.r-project.org/src/contrib/Archive/nloptr/nloptr_1.2.2.tar.gz
Url = 'https://cran.r-project.org/src/contrib/Archive/nloptr/nloptr_1.2.2.tar.gz'
install.packages(Url,repos=NULL,type='source')
install.packages('lme4')
rm(list = ls())
Y = c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14,
4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
batch = factor(rep(c("Batch_1", "Batch_2"), each =  10))
# sample_id nested in batch
sample_id = factor(rep(c("A", "B", "C", "D"), each =  5))
table(sample_id, batch)
# make design not symmetric:
sel = 1:18
Y = Y[sel]
batch = batch[sel]
sample_id = sample_id[sel]
table(sample_id, batch)
# My original model, without sample id:
lm = lm(Y ~ batch )
lm
# a mixed effect model with sample id as random effect
library(lme4)
mm = lmer(Y ~ batch + (1|sample_id) )
mm
# a mixed effect model with sample id as random effect
library(lme4)
mm = lmer(Y ~ batch + (1|batch) )
m
mm
# a mixed effect model with sample id as random effect
library(lme4)
mm = lmer(Y ~ batch + (1|sample_id) )
mm
attributes(mm)
model.matrix(mm)
?lme4
?lmer
# a mixed effect model with sample id as random effect
library(lme4,REML=FALSE)
mm = lmer(Y ~ batch + (1|sample_id) )
mm = lmer(Y ~ batch + (1|sample_id),REML=FALSE )
mm
lm
lm
summary(lm)
summary(mm)
summary(lm)
mm
attributes(mm)
mm$Zrt
getME(fm2, "Z")
getME(mm, "Z")
getME(mm, "Z")
install.packages('lme4')
install.packages('RcppArmadillo')
install.packages('bsts')
1+1
load("~/Desktop/tayside_paper/data/all_data.RData")
View(all_data)
View(all_data$k)
install.packages('ar.matrix')
library(ar.matrix)
Q.AR1(50,1,0.9)
tmp = Q.AR1(50,1,0.9)
library(lattice)
levelplot(tmp)
tmp = Q.AR1(50,1,0.9,sparse=T)
levelplot(tmp)
tmp = Q.AR1(50,1,0.9,sparse=F)
levelplot(tmp)
tmp
tmp = as.matrix(tmp)
levelplot(tmp)
tmp
1181/7
684/4
496/4
520/4
496/4
534/3
178/2
library(rstan)
?stan
expo_covar = function(x,rho) {
CVR = 0*X
CVR = exp(- 0.5*x*x/rho^2)
return(CVR)
}
nTimes = 80
Times = 0:(nTimes-1)/(nTimes-1)
Times
expo_covar = function(x,rho) {
CVR = 0*X
CVR = exp(- 0.5*x*x/rho^2)
return(CVR)
}
nTimes = 80
Times = 0:(nTimes-1)/(nTimes-1)
plot(Times,expo_covar(Times,0.1))
expo_covar = function(x,rho) {
CVR = 0*x
CVR = exp(- 0.5*x*x/rho^2)
return(CVR)
}
nTimes = 80
Times = 0:(nTimes-1)/(nTimes-1)
plot(Times,expo_covar(Times,0.1))
plot(Times,expo_covar(Times,0.1),type='l')
lines(Times,expo_covar(Times,0.01),col=2)
plot(Times,expo_covar(Times,0.1),type='l')
lines(Times,expo_covar(Times,0.5),col=2)
?stan
library(rstan)
?stan
expo_covar = function(x,rho) {
CVR = 0*x
CVR = exp(- 0.5*x*x/rho^2)
return(CVR)
}
nTimes = 80
Times = 0:(nTimes-1)/(nTimes-1)
plot(Times,expo_covar(Times,0.1),type='l')
lines(Times,expo_covar(Times,0.5),col=2)
plot(Times,expo_covar(Times,0.1),type='l')
lines(Times,expo_covar(Times,0.5),col=2)
lines(Times,expo_covar(Times,0.05),col=3)
hist(rgamma(10000,shape=10,rate=100))
?stan
1750*5
500*5
50*5
250*5
hist(100)
30*500
30*500/60
30+13+13+16+1025+89+15+25+25+55+90+160+200
2900-1756
1144-500
644/4.5
30+13+13+16+1025+89+15+25+25+55+90+160+200+60
2900-1816
2900-1816-500
584/4.5
setwd("~/Documents/cbfa")
rm(list=ls())
Sys.setenv("PKG_CXXFLAGS"="-fopenmp -std=c++11")
library(Rcpp)
sourceCpp('./src/cbfa.cpp')
load('./R/dataset_vignette.RData')
rm(list=ls())
Sys.setenv("PKG_CXXFLAGS"="-fopenmp -std=c++11")
library(Rcpp)
sourceCpp('./src/cbfa.cpp')
load('./R/dataset_vignette.RData')
